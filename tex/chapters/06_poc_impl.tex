\section{Prototypical service mesh implementation}

The following chapter describes our concept of our prototypical service mesh implementation and its outcome. In order to also practically work out the differences between service meshes and a traditional microservice operation, we will initially run our application using only Kubernetes, and then later set up a service mesh.

\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{img/diagram-draft.pdf}
    \caption{Architecture overview of the PoC application}
    \label{fig:poc-overview}
\end{figure*}

\subsection{Services}

Our basic idea is to implement three simple microservice applications that communicate via REST. To prove technology independence, one service is written in Node.js, while the other two services are written in Python. Another requirement to meet is that the services have to be as simple as possible. Furthermore, the functionality of the services is intended to be as follows:

\begin{itemize}
\item \textsc{name-service}: Provides endpoint to retrieve a collection of names. It stores the names in a file or a simple array list.
\item \textsc{goodbye-world-service}: Provides endpoint to retrieve a message ``Goodbye, World!"
\item \textsc{hello-world-service}: Contacts the \textsc{name-service} and provides an endpoint that returns a ``Hello, \{name\}" message for each name object from name service.
\end{itemize}

Since Linkerd does not provide an own ingress controller (see chapter \ref{linkerd}), we use an external ingress controller named \textsc{traefik}.

\subsection{Showcases}

Our prototypical implementation aims to provide answers to the following five challenges of running and maintaining microservices.

\subsubsection{Encryption}

By using a service mesh, it should be shown that an encryption policy can be easily applied or removed.

\subsubsection{Canary Deployment}

To provide an example showcase for canary deployment, we implemented two versions of \textsc{goodbye-world-service} which differ minimally by the returned string. The mesh is tasked with redirecting traffic so that 90\% of all requests are made to version 1 and 10\% of requests are made to version 2.

\subsubsection{Access Policies}

Another restriction is that the \textsc{name-service} is only accessible from the \textsc{hello-world-service}. Access restriction should not be a task of the actual \textsc{name-service} application. We want to show that access to services is easily managable via YAML resources.

\subsubsection{Load Balancing}
To encapsulate the services, a \textsc{gateway-service} has to be implemented. The gateway forwards the requests to the \textsc{hello-world-service} and \textsc{goodbye-world-service}. It also balances the load of requests.

\subsubsection{Central monitoring and logging}
The proof of concept should show that services in a microservice landscape can be monitored and managed centrally using the service mesh.

\subsection{Setup of Linkerd}

The following sequence of bash commands shows the \textsc{Linkerd} installation process and the application of the service mesh to the \textsc{Kubernetes} cluster \cite{linkerd-get-started}:
\begin{lstlisting}[language=bash,caption={Setup of \textsc{Linkerd}}, label={lst:linkerd-setup}]
#!/bin/bash
curl -sL https://run.linkerd.io/install \
	| sh
export PATH=$PATH:$HOME/.linkerd2/bin
echo "export PATH=$PATH:$HOME/.linkerd2/bin" \
	>> ~/.bashrc
linkerd install | kubectl apply -f -
\end{lstlisting}

\begin{itemize}
	\item Install linkerd
\begin{itemize}
	\item wir kümmern uns nicht um Verschlüsselung; das macht Linkerd
	\item linkerd install | Kubectl apply -f -
	\item ab diesem Moment mTSL aktiviert
	\item Pipes
\begin{itemize}
	\item this is a usual workflow: Linkerd’s output is a yaml-file, that can be piped into Kubectl 
\end{itemize}
\end{itemize}
	\item wie bekommen wir die µS's ins SM, 
\begin{itemize}
	\item similar to the installation we inject the Linkerd command:
	\item injecten $\rightarrow$ schon im Text drin
\begin{itemize}
	\item entweder einzeln, 
	\item oder für alle folgenden
\end{itemize}
	\item Linkerd parses the yaml file(s) and provides annotations.
\begin{itemize}
	\item Zeige Annotation in Listing
\begin{itemize}
	\item \lstinline|linkerd.io/inject: enabled|
\end{itemize}
\end{itemize}
	\item resulting annotated yaml-file is given to Kubectl as parameter in file option (-f)
\begin{itemize}
	\item dies erzeugt Linkerd-Proxy
\end{itemize}
\end{itemize}
	\item Kommunikation der µS
\begin{itemize}
	\item da im gleichen Namespace, kein Problem
	\item K8s sorgt dafür, dass sie im selben Netz sind
	\item erreichen durch K8s-DNS Namen
\begin{itemize}
	\item setzen sich immer so zusammen
\end{itemize}
	\item diese in yml setzen
	\item Listing?
	\item µS A kann nun die REST-API von µS B unter dieser DNS nutzen
\end{itemize}
	\item Monitoring kommt "out-of-box"
\begin{itemize}
	\item Linkerd kommt mit Prometheus und Grafana
	\item Wir können sehen, wer mit wem wieviel redet
	\item Bsp. Baum aus Linkerd? helloworld spricht mir nameapi?
\end{itemize}
	\item jetzt haben wir schon SM, mTLS und Monitoring 
	\item Ingress Controller
\begin{itemize}
	\item wie kommen wir nun von außen an unserer Services?
	\item wir brauchen einen Ingress Controller
	\item as stated in V-B we chose Traefik
	\item Der kann zwar mehr, aber mehr brauchen wir nicht 
	\item nutzen ihn nur als remote proxy "vor" unseren Services
	\item Wenn injected, nutzen wir Traefik auch als LoadBalancer
\begin{itemize}
	\item \url{https://linkerd.io/2/tasks/using-ingress/} $\rightarrow$ HONOR ;)
\end{itemize}
\end{itemize}
	\item für Detail bzgl Installation und Nutzung bzw. siehe Repo (Anhang)
\end{itemize}



\subsection{Resource definition for applications}

\subsection{Policy application}